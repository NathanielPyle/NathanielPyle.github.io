<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Portuguese Vinho Verde wine quality dataset</title>

<script src="site_libs/header-attrs-2.27/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/darkly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Nathaniel Pyle</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="project.html">Projects</a>
</li>
<li>
  <a href="aboutme.html">About Myself</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Portuguese Vinho Verde wine quality
dataset</h1>

</div>


<div id="overview" class="section level2">
<h2>Overview</h2>
<ul>
<li><strong>Description</strong>: The quality of wine is determined by
various features that relate to its taste, aroma, and other
characteristics familiar to wine experts. The UC Irvine Wine Dataset,
available at <a
href="https://archive.ics.uci.edu/dataset/186/wine+quality">UC Irvine
Wine Dataset</a>, consists of two datasets: one for white wine and one
for red wine. These datasets evaluate wine quality using physicochemical
tests and sensory variables, focusing on the red and white variants of
Portuguese Vinho Verde wine.</li>
</ul>
<p>The dataset includes 11 features and one dependent variable, the wine
quality score. The features, which are based on physicochemical inputs
and sensory data, include: fixed acidity, volatile acidity, citric acid,
residual sugar, chlorides, free sulphur dioxide, total sulphur dioxide,
density, pH, sulphates, and alcohol. These measurements were taken based
on sensory evaluations, with a median score determined from at least
three wine expertsâ€™ assessments.</p>
<p>Each expert graded the wine samples on a scale from 0 (very bad) to
10 (excellent). Due to privacy and logistical constraints, only
physicochemical inputs and sensory outputs are available in this
dataset. No information about grape type, wine brand, or other
confounding variables is provided.</p>
<p>Notably, the datasets contains no missing data.</p>
<p>The aim of this project was to identify the key variables that
influence wine quality. To achieve this, various data science techniques
were applied, including correlation matrices, subset selection, model
evaluation, stepwise selection, validation and cross-validation using
K-folds, as well as Ridge and Lasso regression.</p>
<p>For the full code, this can be accessed via the github account <a
href="https://github.com/NathanielPyle/NathanielPyle.github.io">Nathaniel
Pyle</a></p>
</div>
<div id="methodology" class="section level2">
<h2>Methodology</h2>
<ul>
<li><p><strong>Technologies</strong>: the packages that were used in
this project were <code>corrplot</code>, <code>readODS</code>,
<code>ISLR</code>, <code>leaps</code>, and <code>glmnet</code>.</p></li>
<li><p><strong>Methods</strong>: The columns in both datasets were
assigned names from the accompanying README. Initially, correlation
matrices were created to show basic correlations between variables. To
no avail, these correlation matrices provided little information about
which variables were the most important, nor the nature of the data
itself. Thus, a series of specified Data Science techniques were
employed.</p></li>
<li><p><strong>Subset Selection and R-Squared
Methodology</strong></p></li>
</ul>
<p>To overcome the limitations of correlation matrices, subset selection
was used to analyse the coefficient of determination(R-Squared) across
models as additional variables were incrementally added. Plots were
created to show correlation on the y-axis, and the number of variables
on the x-axis.</p>
<p>These plots indicated that as more variables are added, the R-squared
value increased, meaning the model explains more variance. However,
there is a point of diminishing returns where adding additional
variables no longer significantly improves the modelâ€™s performance.
Including all variables in the model would increase accuracy but risk
overfitting. This is applicable to both datasets.</p>
<p>Four plots were created to show the number of variables against
Correlation, Adjusted-Correlation, Mallowâ€™s Cp, and Bayesian Information
Criterion(BIC). An optimal point was identified for each plot, except
for the Correlation plot. In addition to these plots, regression subset
plots were generated to show which variables were the most important
with regards to the Correlation, Adjusted R-squared, Mallowâ€™s Cp and
BIC. These are similar to bar charts, and show that the higher the bars,
the more important the variable.</p>
<ul>
<li><strong>Stepwise Selection Models Methodology</strong></li>
</ul>
<p>Next, Stepwise Selection models, both Forward and Backward, were
applied to both datasets. These models aimed to identify the variables
that explained the variance in wine quality. Stepwise Selection helps
reduce overfitting and eliminate unnecessary variables by iteratively
adding and removing variables from the model. Variables not included in
the final model were deemed unimportant.</p>
<p>To validate the findings from subset selection and Stepwise
Selection, with regards to Adjusted-Correlation, Mallowâ€™s Cp and BIC,
validation and cross-validation was performed. To accomplish this, the
data for both datasets was split into training and testing partitions.
These partitions were converted into vectors, and checked to ensure that
only observations for test where present in the test dataset and vice
versa.</p>
<p>Subset selection was used on the training data to identify the best
variables for predicting wine quality, while the testing data was used
to construct a model matrix for predictions.</p>
<ul>
<li><strong>Validation and Cross-Validation Methodology</strong></li>
</ul>
<p>A loop was used to calculate the Mean Squared Error (MSE) for models
with varying numbers of predictors from 1 to 11. For each model,
coefficients were extracted and used to generate predictions by
multiplying them with the appropriate columns of the test model matrix.
In addition to forming predictions, test MSE was also calculated.</p>
<p>These predictions were compared with the actual quality values in the
test dataset to calculate MSE, were stored as validation errors.</p>
<p>The validation errors were analysed to determine which model produced
the lowest test MSE. The purpose of this was to compare the previous
results, to see if there was any consistency with the Subset Regression
and Stepwise Selection methods.</p>
<p>This loop function and the validation errors served as a means of
further validation, while providing test MSE.</p>
<p>It is important to note that while this approach provides a set of
coefficient values for the best model, these values may differ slightly
from those produced by Stepwise Selection models. This variation is
expected due to the random splitting of the data into training and
testing sets. Therefore, the coefficients may be similar but not
identical.</p>
<p>Through the reuse of the previous predict function and in combination
of the â€˜regsubsetsâ€™, a custom prediction function â€˜predict.regsubsetsâ€™
was created.</p>
<p>Using the full dataset, the model selected the best model using the
ideal number of variables from the previous validation errors function.
It is important to note that using that full dataset was chosen instead
of using the training partition because there may be differences from
the corresponding model on the training dataset.</p>
<p>To further validate model selection, a k-fold cross-validation
process where k = 10 was employed. This approach used subset selection
within each of k training sets. To accomplish this, a vector for each k
observation was created, alongside a matrix to store the results. This
resulted in vector with 11 by 10 matrix for result storage. This matrix
served as a means to store the test MSE for all cross-validation for the
best model. The coefficients which has the lowest test MSE was selected
as the best model, for instance if variable 7 had the lowest test MSE,
the best model would be a model with 7 variables.</p>
<p>After the cross-validation process, the average MSE for each model
size was calculated. These values were plotted to determine the optimal
number of variables based on the lowest cross-validation error. These
results will be examined in the results section.</p>
<ul>
<li><strong>Ridge and Lasso Regression Methodology</strong></li>
</ul>
<p>For further validation and referencing, Ridge and Lasso regression
were the final techniques utilised to identify the most important
variables. This method involved creating a matrix (x variable) for both
the white and red wine datasets using all independent variables, while
the response variable (y) was the quality of the wine. A grid of lambda
values from 10^10 and 10-2 where utilised to cover the full range of
scenarios.</p>
<p>To explore Ridge and Lasso regression, the Alpha parameter was
adjusted from 0 to 1. Various lambda values, including 50, 60, and the
optimal minimum, were tested, with the corresponding coefficients
analysed. These coefficients were then used to make predictions on both
the training and testing datasets. The model was fitted on the training
data, and the test MSE was calculated for different lambda values, using
a similar train-test split as in the Stepwise Selection method. An
unpenalised least squares model was also included for comparison.
Cross-validation was used to identify the optimal lambda value that
minimised the test MSE, providing a robust evaluation of the model.
Ridge regression effectively regularised the variables, shrinking the
less important ones towards zero.</p>
<p>Lasso regression used with cross validation was used to determine the
optimal test MSE and the most important variables. Using an alpha value
set to 1, many unimportant variables were fully regularised to zero,
further enhancing model simplicity and parsimoniously.</p>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<ul>
<li><strong>R-Squared for Different Models Selection</strong></li>
</ul>
<p>The results from the white wine dataset were that the model does not
significantly improve after the 7th variable. From the first variable to
the 8th, the correlation increased from 0.1897253 to 0.2817520. At the
8th variable, the model converges and starts to plateu.</p>
<p>In comparison the results for the red wine dataset increase rapidly
from the 1st variable to the 2nd, from a correlation of 0.2267344 to
0.3170024. Interestingly, at the 7th variable the model converges and
begins to plateu. This difference between the white and red wine
datasets indicates that the white wine dataset is less sensitive to
changes in the number of variables, at the R-squared value grew more
steady then the Red wine dataset. With the exponential growth in the Red
wine dataset, increasing the number of variables from 1 to 2, increased
the R-squared value from 0.1897253 to 0.2402312. As the Red wine dataset
converges faster than the white wine model, this may indicate that the
model is more parsimonious.</p>
<ul>
<li><strong>Subset Selection Plots</strong></li>
</ul>
<p>The Adjusted R-squared plot shows the variability in the response
variable. It is important to note that the model adjusts for the number
of predictor variables and penalises multicollinearity. The threshold
appears to be around 8 variables, after which any further increase in
Adjusted R-squared becomes minimal, indicating that additional variables
contribute little to improving the model.</p>
<p>The Mallowâ€™s Cp plot strikes a balance between the number of
variables and the variance. The lowest Cp value is reached with 8
variables, suggesting this is the optimal number. Beyond this point,
additional variables offer little benefit and can be discarded.</p>
<p>The Bayesian Information Criterion (BIC) plot further supports this
conclusion. BIC penalises models that are overly complex, favouring
simpler, more parsimonious ones. This plot also suggests that a model
with 8 variables achieves the most efficient balance between complexity
and performance.</p>
<p>For reference, the 8 variables for the white wine dataset are: fixed
acidity, volatile acidity, residual sugar, free sulphur dioxide,
density, pH, sulphates and alcohol. In comparison, the 7 variables for
the red wine datasets were: fixed acidity, volatile acidity, citric
acid, chlorides, pH, sulphates and alcohol. As these datasets have some
similarity, there is overlap between the same variables.</p>
<p>When applying this reasoning to the red wine dataset, similar
patterns emerge, though with some differences. The Adjusted R-squared
still points towards 8 variables, but Mallowâ€™s Cp and BIC suggest
slightly fewer variables at 7 and 6. This indicates some similarity
between the datasets, while also highlighting that the red wine dataset
requires fewer variables for an optimal balance between bias, variance,
and complexity. Due to this difference, for the white wine dataset 8
variables were used for stepwise selection whereas 7 were used for the
red wine dataset; as an average of Mallowâ€™s Cp, BIC and the Adjusted
R-Squared values.</p>
<p>The regression subset plots show which variables are the most
important in both the white and red wine datasets. It should be noted
that these results are synonymous with the previous subset plots, they
just indicate which variables are the most important features.</p>
<ul>
<li><strong>Stepwise Selection Models</strong></li>
</ul>
<p>As the results for both the White and Red wine datasets were the same
for both Forward and Backwards Stepwise Selection, this indicates that
both models are stable. Using 8 variables for the White wine and 7
variables for the Red wine datasets means that these number of variables
are the most significant features to each modelâ€™s performance. These
results are consistent with the Adjusted R-Squared values, Mallowâ€™s Cp
and BIC from stepwise selection. In addition to this, the values having
the same values for both Forward and Backwards Stepwise Selection
indicates that there are no confounding multicollinearity issues. In the
beginning of this project, correlation matrices were created to show the
relationships variables had with both itself and others. As the results
are the same for both Stepwise Selection methods, this indicates that
the order of the variables were added or subtracted from the model did
not influence the model.</p>
<ul>
<li><strong>Validation</strong></li>
</ul>
<p>Using the loop to select the model with the lowest test MSE, for both
datasets, there is some variation. For the white wine dataset, the for
loop selects a model with 8 variables, which is consistent with the
previous results, however for the red wine dataset the for loop selects
a model with 6 variables. This score of 6 variables is consistent with
the BIC number of variables from Stepwise Selection. Despite being a
slight difference of 1 variable, this is not a huge difference and does
provide both reliability to the previous findings. It is important to
note that 8 and 6 variables were selected as they produce the lowest
number of validation errors out of all 11 possible combinations. In
addition to this, ensuring that the set.seed function is used is crucial
as without this function, the results are inconsistent.</p>
<ul>
<li><strong>Cross-validation</strong></li>
</ul>
<p>The results from k-fold cross validation using the regsubsets, where
k = 10, the mean cross validation errors are calculated for all
variables. For the white wine dataset, the lowest mean cross validation
error was at variable 8 was 0.5762928. For the red wine dataset, the
lowest mean cross validation error was at variable 7 at 0.4258431. For
the white wine dataset, this is validates the previous results however
for the red wine dataset, depending on the method used, the optimal
number of variables will vary between 6 and 7. This is arguably not a
huge difference due to the relatively low number of variables in both
datasets.</p>
<ul>
<li><strong>Ridge Regression</strong></li>
</ul>
<p>Using a wide variety of lambda values, where the lambda value was at
50, 60 and the optimal minimum, were explored,</p>
<p>For the white wine dataset, exploring the Lambda values at 50 meant
that during the training process the lambda was set to 11497.57. The
coefficients for this lambda value were significantly shrunk due to this
large lambda value, as the regularisation effect was strong. This
resulted in l2 Norm or Euclidean Norm, the coefficients were at
0.005259955, close to but not exactly at 0. Increasing the Lambda value
from 50 to 60 resulted in the lambda to be set to 705.4802. The
coefficients for this were much higher at 0.1142905, thus indicating
that the coefficients were not regularised as much.</p>
<p>Using a large lambda value of 4, the test MSE was 0.7170693. Compared
with a model with only an intercept, with a test MSE of 0.8014391, the
model where the lambda value was 4 had a lower test MSE.</p>
<p>The red wine dataset had similar results, where the lambda value was
set to 50 this resulted in lambda to be set to be set to 11497.57. The
coefficients were 0.005259955, which in comparison with the white wine
dataset results which were 0.007035063, indicate that the red wine was
regularised more. Interestingly, both the Lambda value at 60 resulted in
the same lambda values and coefficients as that of the white wine
dataset.</p>
<p>There were similar results with the red wine dataset as with the
white wine dataset. When a large lambda value of 4 was selected, the
test MSE was 0.5720506. Compared with a model with only an intercept,
with a test MSE of 0.6736523, the model where the lambda value was 4 had
a lower test MSE.</p>
<p>Using Cross validation in conjunction with Ridge regression, the
optimal lambda value for the white wine dataset was calculated to be
0.03981824, producing an optimal test MSE at 0.5842903. In comparison,
the optimal lambda value for the red wine dataset was 0.04594162 with a
test MSE of 0.4463444.</p>
<ul>
<li><strong>Lasso Regression</strong></li>
</ul>
<p>For the white wine dataset, the optimal test MSE was calculated at
0.5800447. The non-zero coefficients or important variables that were
determined include: fixed acidity, volatile acidity, citric acid,
residual sugar, chlorides, free sulphur dioxide, total sulfur dioxide,
density, pH and sulphates. This is 10 variables out of a possible 11,
which indicates that the model considers most of the variables to be
important.</p>
<p>In comparison with the red wine dataset, the test MSE was 0.4473456.
The same 10 variables out of the possible 11 were selected. This may
indicate that using complex models such as lasso and ridge regression
may be overfitting the data to the model.</p>
</div>
<div id="visualisations" class="section level2">
<h2>Visualisations</h2>
<p><strong>Correlation Matrix White Wine</strong>: <img
src="images/white_wine_corrplot.png" /></p>
<p><strong>Correlation Matrix Red Wine</strong>: <img
src="images/red_wine_corrplot.png" /></p>
<p><strong>R-Squared for Different Models White Wine</strong>: <img
src="images/R-Squared%20for%20Different%20Models%20White%20Wine.png" /></p>
<p><strong>R-Squared for Different Models Red Wine</strong>: <img
src="images/R-Squared%20for%20Different%20Models%20Red%20Wine.png" /></p>
<p><strong>Number of Variables against RSS, Adjusted Rsq, Cp and BIC
White Wine</strong>: <img
src="images/Number%20of%20variables%20against%20RSQ,%20CP,%20BIC%20and%20RSS%20white%20wine.png" />
<strong>Number of Variables against RSS, Adjusted Rsq, Cp and BIC Red
Wine</strong>: <img
src="images/Number%20of%20variables%20against%20RSQ,%20CP,%20BIC%20and%20RSS%20red%20wine.png" />
<strong>Subset Plots White Wine</strong>: <img
src="images/white_wine_subset_plots.png" /> <strong>Subset Plots Red
Wine</strong>: <img src="images/red_wine_subset_plots.png" />
<strong>Mean Cross-Validation Errors White Wine</strong>: <img
src="images/mean_csv_errors_white_wine.png" /> <strong>Mean
Cross-Validation Errors Red Wine</strong>: <img
src="images/mean_csv_errors_red_wine.png" /> <strong>Cross-Validation
optimal Lambda Ridge Regression White Wine</strong>: <img
src="images/cross_validation_optimal_lambda_ridge_white_wine.png" />
<strong>Cross-Validation optimal Lambda Ridge Regression Red
Wine</strong>: <img
src="images/cross_validation_optimal_lambda_ridge_red_wine.png" />
<strong>Lasso Regression Cross Validation White Wine</strong>: <img
src="images/lasso_regression_cross_validation_white_wine.png" />
<strong>Lasso Regression Cross Validation Red Wine</strong>: <img
src="images/lasso_regression_cross_validation_red_wine.png" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
<p>Using some of the available tools, it is possible to analyse the most
important variables in the wine datasets. It is important to note that
using later methodologies such as Lasso and Ridge Regression were
counterintuitive as they overfitted variables onto the model. Using
Stepwise Selection Models in conjunction with Validation and
Cross-Validation protocols was the ideal protocol as the results were
consistent with each other despite there being some variation.</p>
</div>
<div id="citations" class="section level2">
<h2>Citations</h2>
<p>As requested by the authors of this dataset, they requested this
citation be used.</p>
<p>P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. Modeling
wine preferences by data mining from physicochemical properties. In
Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.</p>
</div>
<div id="further-links" class="section level2">
<h2>Further links</h2>
<p>For further links please access the following url.</p>
<p><a href="http://dx.doi.org/10.1016/j.dss.2009.05.016">Modeling wine
preferences by data mining from physicochemical properties</a></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
